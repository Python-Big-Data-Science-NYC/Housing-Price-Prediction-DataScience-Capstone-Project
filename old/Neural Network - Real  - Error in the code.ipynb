{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/ironfrown/deep-learning-house-price-prediction-keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras import metrics\n",
    "from keras import regularizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Activation\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "from keras.callbacks import TensorBoard, EarlyStopping, ModelCheckpoint\n",
    "from keras.utils import plot_model\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "kc_data_org = pd.read_csv(r'./input/kc_house_data.csv')\n",
    "kc_data = pd.read_pickle('df18featuesy.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        RDEATH2016  RNATURALINC2016  RINTERNATIONALMIG2016  RDOMESTICMIG2016  \\\n",
      "count  8757.000000      8757.000000            8757.000000       8757.000000   \n",
      "mean      9.850174         1.614091               1.219975          0.030908   \n",
      "std       2.426470         3.892970               1.663726          8.960091   \n",
      "min       1.522920       -12.437011              -0.857082        -68.325997   \n",
      "25%       8.256732        -0.815895               0.243078         -4.889880   \n",
      "50%       9.880820         1.351976               0.661376         -0.612531   \n",
      "75%      11.493437         3.787800               1.548359          4.480376   \n",
      "max      21.594684        27.051161              17.903389         72.957977   \n",
      "\n",
      "        RBIRTH2016        HPIUS    mortgrate        unemp          cpi  \\\n",
      "count  8757.000000  8757.000000  8757.000000  8757.000000  8757.000000   \n",
      "mean     11.464265     0.003773    -0.009783    -0.008234     0.001952   \n",
      "std       2.347001     0.003826     0.019136     0.016942     0.003314   \n",
      "min       3.881402    -0.002834    -0.038860    -0.023529    -0.004706   \n",
      "25%       9.987023     0.000187    -0.022727    -0.021505     0.001653   \n",
      "50%      11.338200     0.004791    -0.010101    -0.020000     0.002957   \n",
      "75%      12.692169     0.006039     0.010616     0.012658     0.004400   \n",
      "max      30.045173     0.009195     0.017910     0.017857     0.004763   \n",
      "\n",
      "                AL     ...       RNATURALINC2016 (t-2)  \\\n",
      "count  8757.000000     ...                 8757.000000   \n",
      "mean      0.022725     ...                    1.613553   \n",
      "std       0.149033     ...                    3.892286   \n",
      "min       0.000000     ...                  -12.437011   \n",
      "25%       0.000000     ...                   -0.815895   \n",
      "50%       0.000000     ...                    1.352073   \n",
      "75%       0.000000     ...                    3.782441   \n",
      "max       1.000000     ...                   27.051161   \n",
      "\n",
      "       RINTERNATIONALMIG2016 (t-2)  RDOMESTICMIG2016 (t-2)  RBIRTH2016 (t-2)  \\\n",
      "count                  8757.000000             8757.000000       8757.000000   \n",
      "mean                      1.220258                0.035685         11.463889   \n",
      "std                       1.663533                8.960235          2.346721   \n",
      "min                      -0.857082              -68.325997          3.881402   \n",
      "25%                       0.243314               -4.884238          9.987023   \n",
      "50%                       0.661649               -0.610814         11.338200   \n",
      "75%                       1.548359                4.490023         12.691846   \n",
      "max                      17.903389               72.957977         30.045173   \n",
      "\n",
      "       price (t-2)  HPIUS (t-2)  mortgrate (t-2)  unemp (t-2)    cpi (t-2)  \\\n",
      "count  8757.000000  8757.000000      8757.000000  8757.000000  8757.000000   \n",
      "mean     -0.009675     0.003771        -0.009775    -0.008235     0.001952   \n",
      "std       0.066179     0.003827         0.019138     0.016942     0.003314   \n",
      "min      -0.359436    -0.002834        -0.038860    -0.023529    -0.004706   \n",
      "25%      -0.049791     0.000187        -0.022727    -0.021505     0.001653   \n",
      "50%      -0.001557     0.004791        -0.010101    -0.020000     0.002957   \n",
      "75%       0.038709     0.006039         0.010616     0.012658     0.004400   \n",
      "max       0.107404     0.009195         0.017910     0.017857     0.004763   \n",
      "\n",
      "             price  \n",
      "count  8757.000000  \n",
      "mean     -0.009661  \n",
      "std       0.066180  \n",
      "min      -0.359436  \n",
      "25%      -0.049791  \n",
      "50%      -0.001548  \n",
      "75%       0.038735  \n",
      "max       0.107404  \n",
      "\n",
      "[8 rows x 80 columns]\n"
     ]
    }
   ],
   "source": [
    "# kc_data_org['sale_yr'] = pd.to_numeric(kc_data_org.date.str.slice(0, 4))\n",
    "# kc_data_org['sale_month'] = pd.to_numeric(kc_data_org.date.str.slice(4, 6))\n",
    "# kc_data_org['sale_day'] = pd.to_numeric(kc_data_org.date.str.slice(6, 8))\n",
    "\n",
    "# kc_data = pd.DataFrame(kc_data_org, columns=[\n",
    "#         'sale_yr','sale_month','sale_day',\n",
    "#         'bedrooms','bathrooms','sqft_living','sqft_lot','floors',\n",
    "#         'condition','grade','sqft_above','sqft_basement','yr_built',\n",
    "#         'zipcode','lat','long','sqft_living15','sqft_lot15','price'])\n",
    "\n",
    "label_col = 'price'\n",
    "\n",
    "print(kc_data.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RDEATH2016</th>\n",
       "      <th>RNATURALINC2016</th>\n",
       "      <th>RINTERNATIONALMIG2016</th>\n",
       "      <th>RDOMESTICMIG2016</th>\n",
       "      <th>RBIRTH2016</th>\n",
       "      <th>HPIUS</th>\n",
       "      <th>mortgrate</th>\n",
       "      <th>unemp</th>\n",
       "      <th>cpi</th>\n",
       "      <th>AL</th>\n",
       "      <th>...</th>\n",
       "      <th>RNATURALINC2016 (t-2)</th>\n",
       "      <th>RINTERNATIONALMIG2016 (t-2)</th>\n",
       "      <th>RDOMESTICMIG2016 (t-2)</th>\n",
       "      <th>RBIRTH2016 (t-2)</th>\n",
       "      <th>price (t-2)</th>\n",
       "      <th>HPIUS (t-2)</th>\n",
       "      <th>mortgrate (t-2)</th>\n",
       "      <th>unemp (t-2)</th>\n",
       "      <th>cpi (t-2)</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Year</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2011-01-01</th>\n",
       "      <td>11.632586</td>\n",
       "      <td>0.621868</td>\n",
       "      <td>-0.146322</td>\n",
       "      <td>-1.133994</td>\n",
       "      <td>12.254454</td>\n",
       "      <td>-0.002834</td>\n",
       "      <td>0.010616</td>\n",
       "      <td>-0.021505</td>\n",
       "      <td>0.004763</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2.345519</td>\n",
       "      <td>0.327282</td>\n",
       "      <td>5.836523</td>\n",
       "      <td>11.563952</td>\n",
       "      <td>-0.024568</td>\n",
       "      <td>-0.002834</td>\n",
       "      <td>0.010616</td>\n",
       "      <td>-0.021505</td>\n",
       "      <td>0.004763</td>\n",
       "      <td>-0.077495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-01</th>\n",
       "      <td>9.871136</td>\n",
       "      <td>3.058662</td>\n",
       "      <td>-0.052136</td>\n",
       "      <td>1.807391</td>\n",
       "      <td>12.929798</td>\n",
       "      <td>-0.002834</td>\n",
       "      <td>0.010616</td>\n",
       "      <td>-0.021505</td>\n",
       "      <td>0.004763</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.962947</td>\n",
       "      <td>0.989585</td>\n",
       "      <td>14.768069</td>\n",
       "      <td>11.831760</td>\n",
       "      <td>-0.093731</td>\n",
       "      <td>-0.002834</td>\n",
       "      <td>0.010616</td>\n",
       "      <td>-0.021505</td>\n",
       "      <td>0.004763</td>\n",
       "      <td>-0.086218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-01</th>\n",
       "      <td>12.950211</td>\n",
       "      <td>-1.174622</td>\n",
       "      <td>0.910332</td>\n",
       "      <td>-2.496072</td>\n",
       "      <td>11.775588</td>\n",
       "      <td>-0.002834</td>\n",
       "      <td>0.010616</td>\n",
       "      <td>-0.021505</td>\n",
       "      <td>0.004763</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.621868</td>\n",
       "      <td>-0.146322</td>\n",
       "      <td>-1.133994</td>\n",
       "      <td>12.254454</td>\n",
       "      <td>-0.077495</td>\n",
       "      <td>-0.002834</td>\n",
       "      <td>0.010616</td>\n",
       "      <td>-0.021505</td>\n",
       "      <td>0.004763</td>\n",
       "      <td>-0.194399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-01</th>\n",
       "      <td>11.911623</td>\n",
       "      <td>-3.419789</td>\n",
       "      <td>0.076849</td>\n",
       "      <td>6.109510</td>\n",
       "      <td>8.491835</td>\n",
       "      <td>-0.002834</td>\n",
       "      <td>0.010616</td>\n",
       "      <td>-0.021505</td>\n",
       "      <td>0.004763</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3.058662</td>\n",
       "      <td>-0.052136</td>\n",
       "      <td>1.807391</td>\n",
       "      <td>12.929798</td>\n",
       "      <td>-0.086218</td>\n",
       "      <td>-0.002834</td>\n",
       "      <td>0.010616</td>\n",
       "      <td>-0.021505</td>\n",
       "      <td>0.004763</td>\n",
       "      <td>-0.148970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-01</th>\n",
       "      <td>10.092682</td>\n",
       "      <td>3.397340</td>\n",
       "      <td>1.728471</td>\n",
       "      <td>0.993374</td>\n",
       "      <td>13.490022</td>\n",
       "      <td>-0.002834</td>\n",
       "      <td>0.010616</td>\n",
       "      <td>-0.021505</td>\n",
       "      <td>0.004763</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.174622</td>\n",
       "      <td>0.910332</td>\n",
       "      <td>-2.496072</td>\n",
       "      <td>11.775588</td>\n",
       "      <td>-0.194399</td>\n",
       "      <td>-0.002834</td>\n",
       "      <td>0.010616</td>\n",
       "      <td>-0.021505</td>\n",
       "      <td>0.004763</td>\n",
       "      <td>-0.076972</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            RDEATH2016  RNATURALINC2016  RINTERNATIONALMIG2016  \\\n",
       "Year                                                             \n",
       "2011-01-01   11.632586         0.621868              -0.146322   \n",
       "2011-01-01    9.871136         3.058662              -0.052136   \n",
       "2011-01-01   12.950211        -1.174622               0.910332   \n",
       "2011-01-01   11.911623        -3.419789               0.076849   \n",
       "2011-01-01   10.092682         3.397340               1.728471   \n",
       "\n",
       "            RDOMESTICMIG2016  RBIRTH2016     HPIUS  mortgrate     unemp  \\\n",
       "Year                                                                      \n",
       "2011-01-01         -1.133994   12.254454 -0.002834   0.010616 -0.021505   \n",
       "2011-01-01          1.807391   12.929798 -0.002834   0.010616 -0.021505   \n",
       "2011-01-01         -2.496072   11.775588 -0.002834   0.010616 -0.021505   \n",
       "2011-01-01          6.109510    8.491835 -0.002834   0.010616 -0.021505   \n",
       "2011-01-01          0.993374   13.490022 -0.002834   0.010616 -0.021505   \n",
       "\n",
       "                 cpi  AL    ...     RNATURALINC2016 (t-2)  \\\n",
       "Year                        ...                             \n",
       "2011-01-01  0.004763   1    ...                  2.345519   \n",
       "2011-01-01  0.004763   1    ...                  1.962947   \n",
       "2011-01-01  0.004763   1    ...                  0.621868   \n",
       "2011-01-01  0.004763   1    ...                  3.058662   \n",
       "2011-01-01  0.004763   1    ...                 -1.174622   \n",
       "\n",
       "            RINTERNATIONALMIG2016 (t-2)  RDOMESTICMIG2016 (t-2)  \\\n",
       "Year                                                              \n",
       "2011-01-01                     0.327282                5.836523   \n",
       "2011-01-01                     0.989585               14.768069   \n",
       "2011-01-01                    -0.146322               -1.133994   \n",
       "2011-01-01                    -0.052136                1.807391   \n",
       "2011-01-01                     0.910332               -2.496072   \n",
       "\n",
       "            RBIRTH2016 (t-2)  price (t-2)  HPIUS (t-2)  mortgrate (t-2)  \\\n",
       "Year                                                                      \n",
       "2011-01-01         11.563952    -0.024568    -0.002834         0.010616   \n",
       "2011-01-01         11.831760    -0.093731    -0.002834         0.010616   \n",
       "2011-01-01         12.254454    -0.077495    -0.002834         0.010616   \n",
       "2011-01-01         12.929798    -0.086218    -0.002834         0.010616   \n",
       "2011-01-01         11.775588    -0.194399    -0.002834         0.010616   \n",
       "\n",
       "            unemp (t-2)  cpi (t-2)     price  \n",
       "Year                                          \n",
       "2011-01-01    -0.021505   0.004763 -0.077495  \n",
       "2011-01-01    -0.021505   0.004763 -0.086218  \n",
       "2011-01-01    -0.021505   0.004763 -0.194399  \n",
       "2011-01-01    -0.021505   0.004763 -0.148970  \n",
       "2011-01-01    -0.021505   0.004763 -0.076972  \n",
       "\n",
       "[5 rows x 80 columns]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kc_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_validate_test_split(df, train_part=.6, validate_part=.2, test_part=.2, seed=None):\n",
    "    np.random.seed(seed)\n",
    "    total_size = train_part + validate_part + test_part\n",
    "    train_percent = train_part / total_size\n",
    "    validate_percent = validate_part / total_size\n",
    "    test_percent = test_part / total_size\n",
    "    perm = np.random.permutation(df.index)\n",
    "    m = len(df)\n",
    "    train_end = int(train_percent * m)\n",
    "    validate_end = int(validate_percent * m) + train_end\n",
    "    train = perm[:train_end]\n",
    "    validate = perm[train_end:validate_end]\n",
    "    test = perm[validate_end:]\n",
    "    return train, validate, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size, valid_size, test_size = (70, 30, 0)\n",
    "kc_train, kc_valid, kc_test = train_validate_test_split(kc_data, \n",
    "                              train_part=train_size, \n",
    "                              validate_part=valid_size,\n",
    "                              test_part=test_size,\n",
    "                              seed=2017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of training set:  9017747\n",
      "Size of validation set:  3857476\n",
      "Size of test set:  1 (not converted)\n"
     ]
    }
   ],
   "source": [
    "kc_y_train = kc_data.loc[kc_train, [label_col]]\n",
    "kc_x_train = kc_data.loc[kc_train, :].drop(label_col, axis=1)\n",
    "kc_y_valid = kc_data.loc[kc_valid, [label_col]]\n",
    "kc_x_valid = kc_data.loc[kc_valid, :].drop(label_col, axis=1)\n",
    "\n",
    "print('Size of training set: ', len(kc_x_train))\n",
    "print('Size of validation set: ', len(kc_x_valid))\n",
    "print('Size of test set: ', len(kc_test), '(not converted)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_stats(df1, df2):\n",
    "    dfs = df1.append(df2)\n",
    "    minimum = np.min(dfs)\n",
    "    maximum = np.max(dfs)\n",
    "    mu = np.mean(dfs)\n",
    "    sigma = np.std(dfs)\n",
    "    return (minimum, maximum, mu, sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def z_score(col, stats):\n",
    "    m, M, mu, s = stats\n",
    "    df = pd.DataFrame()\n",
    "    for c in col.columns:\n",
    "        df[c] = (col[c]-mu[c])/s[c]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training shape: (9017747, 79)\n",
      "Training samples:  9017747\n",
      "Validation samples:  3857476\n"
     ]
    }
   ],
   "source": [
    "stats = norm_stats(kc_x_train, kc_x_valid)\n",
    "arr_x_train = np.array(z_score(kc_x_train, stats))\n",
    "arr_y_train = np.array(kc_y_train)\n",
    "arr_x_valid = np.array(z_score(kc_x_valid, stats))\n",
    "arr_y_valid = np.array(kc_y_valid)\n",
    "\n",
    "print('Training shape:', arr_x_train.shape)\n",
    "print('Training samples: ', arr_x_train.shape[0])\n",
    "print('Validation samples: ', arr_x_valid.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(arr_x_train).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_model_1(x_size, y_size):\n",
    "    t_model = Sequential()\n",
    "    t_model.add(Dense(100, activation=\"tanh\", input_shape=(x_size,)))\n",
    "    t_model.add(Dense(50, activation=\"relu\"))\n",
    "    t_model.add(Dense(y_size))\n",
    "    print(t_model.summary())\n",
    "    t_model.compile(loss='mean_squared_error',\n",
    "        optimizer=Adam(),\n",
    "        metrics=[metrics.mae])\n",
    "    return(t_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_model_2(x_size, y_size):\n",
    "    t_model = Sequential()\n",
    "    t_model.add(Dense(100, activation=\"tanh\", input_shape=(x_size,)))\n",
    "    t_model.add(Dropout(0.1))\n",
    "    t_model.add(Dense(50, activation=\"relu\"))\n",
    "    t_model.add(Dense(20, activation=\"relu\"))\n",
    "    t_model.add(Dense(y_size))\n",
    "    print(t_model.summary())\n",
    "    t_model.compile(loss='mean_squared_error',\n",
    "        optimizer=Adam(),\n",
    "        metrics=[metrics.mae])\n",
    "    return(t_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_model_3(x_size, y_size):\n",
    "    t_model = Sequential()\n",
    "    t_model.add(Dense(80, activation=\"tanh\", kernel_initializer='normal', input_shape=(x_size,)))\n",
    "    t_model.add(Dropout(0.2))\n",
    "    t_model.add(Dense(120, activation=\"relu\", kernel_initializer='normal', \n",
    "        kernel_regularizer=regularizers.l1(0.01), bias_regularizer=regularizers.l1(0.01)))\n",
    "    t_model.add(Dropout(0.1))\n",
    "    t_model.add(Dense(20, activation=\"relu\", kernel_initializer='normal', \n",
    "        kernel_regularizer=regularizers.l1_l2(0.01), bias_regularizer=regularizers.l1_l2(0.01)))\n",
    "    t_model.add(Dropout(0.1))\n",
    "    t_model.add(Dense(10, activation=\"relu\", kernel_initializer='normal'))\n",
    "    t_model.add(Dropout(0.0))\n",
    "    t_model.add(Dense(y_size))\n",
    "    t_model.compile(\n",
    "        loss='mean_squared_error',\n",
    "        optimizer='nadam',\n",
    "        metrics=[metrics.mae])\n",
    "    return(t_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_13 (Dense)             (None, 100)               8000      \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 13,101\n",
      "Trainable params: 13,101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_13 (Dense)             (None, 100)               8000      \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 13,101\n",
      "Trainable params: 13,101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = basic_model_1(arr_x_train.shape[1], arr_y_train.shape[1])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs:  50\n",
      "Batch size:  128\n"
     ]
    }
   ],
   "source": [
    "epochs = 50\n",
    "batch_size = 128\n",
    "\n",
    "print('Epochs: ', epochs)\n",
    "print('Batch size: ', batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_callbacks = [\n",
    "    # ModelCheckpoint('/tmp/keras_checkpoints/model.{epoch:02d}-{val_loss:.2f}.hdf5', monitor='val_loss', save_best_only=True, verbose=2)\n",
    "    # ModelCheckpoint('/tmp/keras_checkpoints/model.{epoch:02d}.hdf5', monitor='val_loss', save_best_only=True, verbose=0)\n",
    "    # TensorBoard(log_dir='/tmp/keras_logs/model_3', histogram_freq=0, write_graph=True, write_images=True, embeddings_freq=0, embeddings_layer_names=None, embeddings_metadata=None),\n",
    "    EarlyStopping(monitor='val_mean_absolute_error', patience=20, verbose=0)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-108-5f3fb9a9effb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;31m# Change it to 2, if wished to observe execution\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr_x_valid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marr_y_valid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     callbacks=keras_callbacks)\n\u001b[0m",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m    961\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    962\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 963\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m    964\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    965\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1705\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1706\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[1;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m   1233\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1234\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1235\u001b[1;33m                     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1236\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1237\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2476\u001b[0m         \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2477\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[1;32m-> 2478\u001b[1;33m                               **self.session_kwargs)\n\u001b[0m\u001b[0;32m   2479\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2480\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    787\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 789\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    790\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    995\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    996\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m--> 997\u001b[1;33m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[0;32m    998\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    999\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1130\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1131\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[1;32m-> 1132\u001b[1;33m                            target_list, options, run_metadata)\n\u001b[0m\u001b[0;32m   1133\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1137\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1138\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1139\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1140\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1141\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1119\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[0;32m   1120\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1121\u001b[1;33m                                  status, run_metadata)\n\u001b[0m\u001b[0;32m   1122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1123\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(arr_x_train, arr_y_train,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    shuffle=True,\n",
    "    verbose=0, # Change it to 2, if wished to observe execution\n",
    "    validation_data=(arr_x_valid, arr_y_valid),\n",
    "    callbacks=keras_callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_score = model.evaluate(arr_x_train, arr_y_train, verbose=0)\n",
    "valid_score = model.evaluate(arr_x_valid, arr_y_valid, verbose=0)\n",
    "\n",
    "print('Train MAE: ', round(train_score[1], 4), ', Train Loss: ', round(train_score[0], 4)) \n",
    "print('Val MAE: ', round(valid_score[1], 4), ', Val Loss: ', round(valid_score[0], 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hist(h, xsize=6, ysize=10):\n",
    "    # Prepare plotting\n",
    "    fig_size = plt.rcParams[\"figure.figsize\"]\n",
    "    plt.rcParams[\"figure.figsize\"] = [xsize, ysize]\n",
    "    fig, axes = plt.subplots(nrows=4, ncols=4, sharex=True)\n",
    "    \n",
    "    # summarize history for MAE\n",
    "    plt.subplot(211)\n",
    "    plt.plot(h['mean_absolute_error'])\n",
    "    plt.plot(h['val_mean_absolute_error'])\n",
    "    plt.title('Training vs Validation MAE')\n",
    "    plt.ylabel('MAE')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "    \n",
    "    # summarize history for loss\n",
    "    plt.subplot(212)\n",
    "    plt.plot(h['loss'])\n",
    "    plt.plot(h['val_loss'])\n",
    "    plt.title('Training vs Validation Loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "    \n",
    "    # Plot it all in IPython (non-interactive)\n",
    "    plt.draw()\n",
    "    plt.show()\n",
    "\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hist(history.history, xsize=8, ysize=12)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred= model.predict(kc_x_valid)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = arr_y_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(y_true, y_pred, multioutput='variance_weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.metrics import classification_report,confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import explained_variance_score\n",
    "explained_variance_score(y_true, y_pred) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
